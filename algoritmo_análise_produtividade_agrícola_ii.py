# -*- coding: utf-8 -*-
"""Algoritmo_Análise Produtividade agrícola II.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vyI5m_8797mBh7IpUwBQQQhzmfyCgo9A
"""

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

# Read the Excel file
df_cana = pd.read_excel('Base de dados_Oficial.xlsx', sheet_name='Planilha2')

print("--- Análise Inicial do DataFrame de Cana-de-Açúcar (df_cana) ---")

# Exibir as primeiras linhas para ter uma ideia dos dados
print("\nPrimeiras 5 linhas do DataFrame df_cana:")
print(df_cana.head())

# Exibir informações gerais sobre o DataFrame (tipos de dados, contagem de não-nulos)
print("\nInformações do DataFrame df_cana:")
df_cana.info()

# Exibir a contagem de valores nulos por coluna
print("\nContagem de valores nulos por coluna em df_cana:")
print(df_cana.isnull().sum())

# Exibir os nomes das colunas para verificar a grafia exata
print("\nNomes das colunas em df_cana:")
print(df_cana.columns.tolist())

from google.colab import drive
drive.mount('/content/drive')

#Tratamentos iniciais
#Imputação pela mediana é a abordagem mais robusta e simples. A mediana é menos sensível a outliers do que a média.
#Tratamento de Multicolinearidade: Faremos a mesma simplificação que fizemos para o milho. Removeremos 'Material Particulado (PM10) µg/m3', 'Óxidos de nitrogênio (NO) µg/m3' e 'Óxidos de nitrogênio (NO₂)', mantendo 'Material Particulado (PM2.5) µg/m3' e 'Óxidos de nitrogênio (NOₓ)'.

import pandas as pd
import numpy as np

# Assumindo que df_cana foi carregado na célula anterior

print("--- Pré-processamento e Tratamento para Cana-de-Açúcar (df_cana) ---")

# 1. Tratamento de Dados Ausentes
# Para 'Número de dias com chuva' e 'Precipitação (mm)', preencher com a mediana da coluna
print("\nValores nulos antes da imputação (Número de dias com chuva, Precipitação (mm)):")
print(df_cana[['Número de dias com chuva', 'Precipitação (mm)']].isnull().sum())

if 'Número de dias com chuva' in df_cana.columns:
    median_dias_chuva = df_cana['Número de dias com chuva'].median()
    df_cana['Número de dias com chuva'].fillna(median_dias_chuva, inplace=True)
    df_cana['Número de dias com chuva'] = df_cana['Número de dias com chuva'].astype(int) # Converter para int, pois são dias

if 'Precipitação (mm)' in df_cana.columns:
    median_precipitacao = df_cana['Precipitação (mm)'].median()
    df_cana['Precipitação (mm)'].fillna(median_precipitacao, inplace=True)

print("\nValores nulos após a imputação:")
print(df_cana.isnull().sum())


# 2. Tratamento da Multicolinearidade (Seleção de Variáveis)
print("\nColunas antes da seleção de variáveis para multicolinearidade:")
print(df_cana.columns.tolist())

columns_to_drop_multicollinearity_cana = [
    'Material Particulado (PM10) µg/m3',
    'Óxidos de nitrogênio (NO) µg/m3',
    'Óxidos de nitrogênio (NO₂)'
]

# Remover as colunas do DataFrame, criando um novo DataFrame limpo para cana
df_cana_cleaned = df_cana.drop(columns=columns_to_drop_multicollinearity_cana, errors='ignore')

print("\nColunas após a seleção de variáveis para tratar multicolinearidade:")
print(df_cana_cleaned.columns.tolist())

print("\nInformações do DataFrame df_cana_cleaned após limpeza e seleção:")
df_cana_cleaned.info()

print("\nPrimeiras 5 linhas do DataFrame df_cana_cleaned:")
print(df_cana_cleaned.head())

#Modelagem com Random Forest Regressor para Cana-de-Açúcar

# Import necessary libraries
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import KFold # Adicionando KFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

# Assumindo que 'df_cana_cleaned' é o DataFrame resultante da célula anterior

# 1. Preparação dos dados para o modelo
# A variável alvo para a cana-de-açúcar
target_variable_cana = 'Quantidade de cana produzida (Toneladas)'

# As variáveis preditoras (features)
# Excluindo 'Ano' e o target
features_to_exclude_cana = [
    target_variable_cana,
    'Ano'
]

# Selecionar todas as colunas numéricas e depois remover as excluídas
numeric_cols_cana = df_cana_cleaned.select_dtypes(include=np.number).columns.tolist()
features_cana = [col for col in numeric_cols_cana if col not in features_to_exclude_cana]

# Exibir as features que serão usadas
print("\nVariáveis preditoras (Features) para o modelo Random Forest (Cana - agregadas anualmente):")
print(features_cana)

X_cana = df_cana_cleaned[features_cana]
y_cana = df_cana_cleaned[target_variable_cana]

# Verifique se há NaNs restantes em X_cana ou y_cana (deve ser 0 agora)
if X_cana.isnull().sum().sum() > 0 or y_cana.isnull().sum() > 0:
    print("\nAVISO: Existem valores NaN em X_cana ou y_cana antes do treinamento do modelo. Verifique a etapa de limpeza de dados.")
    print("NaNs em X_cana:\n", X_cana.isnull().sum()[X_cana.isnull().sum() > 0])
    print("NaNs em y_cana:\n", y_cana.isnull().sum())


# --- Usando Validação Cruzada K-Fold devido ao pequeno tamanho do dataset ---
# Com apenas 11 amostras, um KFold de 5 (k=5) significa que em cada iteração:
# (~2-3 amostras para teste e ~8-9 para treino).
kf_cana = KFold(n_splits=5, shuffle=True, random_state=42) # shuffle para embaralhar os dados

rmse_scores_cana = []
r2_scores_cana = []
feature_importances_accumulated_cana = np.zeros(len(features_cana))

print(f"\nIniciando Treinamento e Avaliação com K-Fold Cross Validation (k=5) para Cana-de-Açúcar...")
fold = 1
for train_index, test_index in kf_cana.split(X_cana):
    print(f"\n--- Fold {fold} ---")
    X_train_fold_cana, X_test_fold_cana = X_cana.iloc[train_index], X_cana.iloc[test_index]
    y_train_fold_cana, y_test_fold_cana = y_cana.iloc[train_index], y_cana.iloc[test_index]

    # 3. Inicialização e Treinamento do Modelo Random Forest Regressor
    model_rf_cana = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model_rf_cana.fit(X_train_fold_cana, y_train_fold_cana)

    # 4. Avaliação do Modelo para o Fold Atual
    y_pred_rf_cana = model_rf_cana.predict(X_test_fold_cana)

    rmse_fold_cana = np.sqrt(mean_squared_error(y_test_fold_cana, y_pred_rf_cana))
    r2_fold_cana = r2_score(y_test_fold_cana, y_pred_rf_cana)

    rmse_scores_cana.append(rmse_fold_cana)
    r2_scores_cana.append(r2_fold_cana)

    print(f"RMSE (Fold {fold}): {rmse_fold_cana:.2f}")
    print(f"R² (Fold {fold}): {r2_fold_cana:.2f}")

    # Acumular importância das features para média
    feature_importances_accumulated_cana += model_rf_cana.feature_importances_
    fold += 1

print(f"\n--- Avaliação Média do Modelo Random Forest (K-Fold - Cana-de-Açúcar) ---")
print(f"RMSE Médio: {np.mean(rmse_scores_cana):.2f} (± {np.std(rmse_scores_cana):.2f})")
print(f"R² Médio: {np.mean(r2_scores_cana):.2f} (± {np.std(r2_scores_cana):.2f})")

# 5. Análise de Importância das Features (Média sobre os folds)
if not X_cana.empty and hasattr(model_rf_cana, 'feature_importances_'):
    feature_importances_mean_cana = feature_importances_accumulated_cana / kf_cana.get_n_splits()
    forest_importances_mean_cana = pd.Series(feature_importances_mean_cana, index=X_cana.columns).sort_values(ascending=False)

    fig, ax = plt.subplots(figsize=(12, 8))
    forest_importances_mean_cana.plot.bar(ax=ax)
    ax.set_title("Importância Média das Features (Random Forest - Cana-de-Açúcar - K-Fold)")
    ax.set_ylabel("Média da Redução de Impureza")
    plt.tight_layout()
    plt.show()
else:
    print("\nNão foi possível calcular a importância das features (dados insuficientes ou modelo não treinado).")

# 6. Visualização das Previsões vs. Valores Reais (Opcional, mais complexo com K-Fold para um único gráfico)
# Será difícil visualizar com apenas 11 pontos, mas as métricas médias já são a principal informação.

"""Variáveis como Material Particulado (PM2.5) µg/m3, Ozônio (O₃) µg/m3 e Óxidos de nitrogênio (NOₓ) novamente mostram importância muito baixa ou quase nula, similar ao que vimos com o milho. Isso sugere que, para a cana-de-açúcar também, o modelo não está conseguindo encontrar uma relação preditiva significativa com esses poluentes.

----

Diagnóstico Final para Cana-de-Açúcar e Conclusões Amplas
Os resultados do modelo Random Forest para a cana-de-açúcar são ainda mais desafiadores do que para o milho. O R
2
  médio extremamente negativo, combinado com a alta variabilidade do RMSE entre os folds, reforça as conclusões que tiramos para o milho e as amplia para a cana.

Pontos Chave:

Dataset Pequeníssimo: Com apenas 11 amostras anuais para a cana-de-açúcar, é extremamente difícil para qualquer modelo de Machine Learning aprender e generalizar padrões. A robustez da validação cruzada K-Fold ajuda a dar uma estimativa mais realista do desempenho médio, mas não pode compensar a falta de volume de dados.
Variabilidade do Target e Qualidade dos Dados: O comportamento do R
2
  negativo em todos os folds e a grande dispersão do RMSE sugerem que a variável alvo (Quantidade de cana produzida (Toneladas)) pode ter uma variabilidade intrínseca que não é explicada pelas features disponíveis, ou que a relação é muito ruidosa/não existente com essas variáveis, dado o volume de dados.
Pouca Correlação das Variáveis Atmosféricas: A importância insignificante dos poluentes e queimadas para a cana-de-açúcar reitera que, com os dados atuais, não foi possível demonstrar um impacto preditivo claro dessas variáveis na produtividade, um achado consistente com o milho.
Implicações para o TCC:

Para a cana-de-açúcar, a conclusão será a mesma (ou até mais enfática) do que para o milho: com os dados disponíveis (especialmente o tamanho limitado do dataset anual), não foi possível construir um modelo preditivo robusto para a produtividade da cana-de-açúcar utilizando as variáveis climáticas e atmosféricas analisadas.
"""